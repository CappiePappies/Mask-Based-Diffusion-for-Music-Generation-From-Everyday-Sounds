# Mask-Based-Diffusion-for-Music-Generation-From-Everyday-Sounds
We present a generative AI method for music creation from everyday sounds using spectrogram-based diffusion. By adding custom masking to the Img2Img pipeline with prompt-driven style conditioning, our approach preserves input sound features while enabling flexible, fine-grained stylistic control for creative audio synthesis.
